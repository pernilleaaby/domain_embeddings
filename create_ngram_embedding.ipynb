{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c2098b9",
   "metadata": {},
   "source": [
    "# Create ngram embedding\n",
    "A ngram of words is just a set of words: \n",
    "- Monograms: \"of\", \"words\", \"is\"\n",
    "- Bigrams: \"of words\", \"words is\", \"is just\"\n",
    "- Trigrams: \"of words is\", \"words is just\"\n",
    "- etc. \n",
    "\n",
    "A word-embedding is a vector representation of a word (random, simplified examples): \n",
    "- \"of\" -> [2, 6, -1]\n",
    "- \"words\" -> [-2, 3, 9]\n",
    "- \"just\" -> [9, 9, -3]\n",
    "\n",
    "The nice thing about word-embeddings is that you can compare words using mathematical functions like cosine similarity (cos_sim): \n",
    "- cos_sim(vector(\"cat\"), vector(\"tiger\")) = 0.95, where cos_sim is a score of similarity between two words. \n",
    "\n",
    "If we would like to find a vector for a ngram more than one we need a pooling function. A pooling function can for example be average, maximum, minimal, absolute maximum etc. \n",
    "- average_pooling([1, 2, 3], [3, 2, 1]) = [4, 4, 4]\n",
    "- abs_max_pooling([-1, -1, -3], [3, 2, 1]) = [3, 2, -3]\n",
    "\n",
    "\n",
    "## Text corpus\n",
    "For this notebook we will extract ngram of words from papers and embed them into ngram-embeddings. \n",
    "When we have the set of ngram-embeddings we can use a similarity function to find \"similar ngrams\" to what you input. \n",
    "We will in this tutorial support .pdf or .txt files. \n",
    "\n",
    "## Contextual model\n",
    "We are not going to train any models in this tutorial, but rather use an existing contextual language model to find our embeddings.\n",
    "\n",
    "These contextual models have often been pre-trained on a massive amount of data, so they already know a lot about a language. \n",
    "\n",
    "## NLP Libraries\n",
    "We introduce a few highly useful NLP- libraries, that you can use for a lot more than what we do in this tutorial!\n",
    "\n",
    "### Huggingface\n",
    "https://huggingface.co/ \n",
    "Huggingface is a library full of useful datasets and pre-trained langugage models, as well as an api to make the work with huge models simple for you. We will use it to download a pre-trained bert-model, but you can acces so many other models as well. \n",
    "If you for example want to download you own multilingual translation model check out facebooks: https://huggingface.co/facebook/m2m100_418M . \n",
    "\n",
    "\n",
    "### Spacy\n",
    "https://spacy.io/ \n",
    "Spacy is also a much used library in NLP. Although we in this tutorial mainly use it for splitting text into sentences, spacy models often has much more functionality. You can f.eks. do Named Entity Recognition, POS-tagging (tag words as verbs, nouns etc). \n",
    "\n",
    "\n",
    "### Gensim\n",
    "https://radimrehurek.com/gensim/intro.html\n",
    "Gensim is a library specialized in representing text as semantic vectors (as out word-embeddings). You can very easily create you own set of word-embeddings or document-embeddings with this library, however we use it mainly to get functionality when comparing the word-embeddings. \n",
    "\n",
    "\n",
    "### Pymupdf\n",
    "https://pymupdf.readthedocs.io/en/latest/\n",
    "Helpful for extracting information such as text or images from pdf-files. \n",
    "\n",
    "\n",
    "### Pytorch \n",
    "https://pytorch.org/\n",
    "Like Tensorflow, Pytorch is a framework for tensor-processing. Compatible with GPU. \n",
    "\n",
    "### Natural Language Toolkit (NLTK)\n",
    "https://www.nltk.org/ \n",
    "Superuseful for tokenization (e.g. creating our ngram of words) and it has a lot of useful lexical resources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be4ed77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glob is used for finding filepaths\n",
    "import glob\n",
    "\n",
    "# regex\n",
    "import re\n",
    "\n",
    "# numpy, useful for efficient vector operations\n",
    "import numpy as np\n",
    "\n",
    "# pymupdf for pdf parsing (I have no idea why it is called fitz...)\n",
    "import fitz\n",
    "\n",
    "# natural langauge toolkit\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# pytorch \n",
    "import torch\n",
    "\n",
    "# transformoer models from huggingface\n",
    "from transformers import BertTokenizerFast, BertModel\n",
    "\n",
    "# spacy library\n",
    "import spacy\n",
    "\n",
    "# gensim library\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "34fb105a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants \n",
    "PDF_FOLDER = \"C:/Users/perni/OneDrive/Dokumenter/1. OsloMet/MasterProject/Papers/*/*.pdf\"\n",
    "NGRAMS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c576061",
   "metadata": {},
   "source": [
    "## Fetch data from pdf-files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ade14e",
   "metadata": {},
   "source": [
    "### Define a few functions for extracting only relevant text\n",
    "Based on the format that pymupdf outputs a parsed pdf we only extract the text. The text is grouped according to which font they use. The aim is then to only extract the text of the main font to avoid bibliography etc. to be included in the text corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebf9f462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_by_font(doc): \n",
    "    text_by_font = {}\n",
    "    for page in doc.pages(): \n",
    "        text_page = page.get_text(\"dict\")\n",
    "        for block in text_page['blocks']: \n",
    "            if ('lines' in block):\n",
    "                for line in block['lines']: \n",
    "                    for span in line['spans']: \n",
    "                        font_id = span['font']+\"_\"+str(round(span['size'])) # font_id equals font + size\n",
    "                        if (font_id in text_by_font): \n",
    "                            text_by_font[font_id] += (\" \"+span['text'])\n",
    "                        else: \n",
    "                            text_by_font.update({font_id: span['text']})\n",
    "    return text_by_font\n",
    "\n",
    "\n",
    "def get_text_font_amount(text_by_font): \n",
    "    token_len_fonts = []\n",
    "    for font_id, text in text_by_font.items(): \n",
    "        token_len = len(text.split())\n",
    "        token_len_fonts.append((token_len, font_id))\n",
    "    # sort so the one with the most tokens are first\n",
    "    token_len_fonts.sort(reverse = True)\n",
    "    return token_len_fonts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b965ad",
   "metadata": {},
   "source": [
    "### Extract text from the given pdf-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c19226b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the filenames,  probably in format: paper_folder/*.pdf \n",
    "filenames = glob.glob(PDF_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30dbb0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/perni/OneDrive/Dokumenter/1. OsloMet/MasterProject/Papers\\Beam search\\beam_blog.pdf\n"
     ]
    }
   ],
   "source": [
    "# iterate through all filenames to extract text from each file\n",
    "text_articles = []\n",
    "\n",
    "for filename in filenames[:20]: \n",
    "    # parse pdf\n",
    "    doc = fitz.open(filename) \n",
    "    if (len(doc) > 20): # we skip very long files\n",
    "        continue \n",
    "    # we use a try catch, because some pdf-files do not work\n",
    "    try: \n",
    "        # find the text belonging to the most common font\n",
    "        text_by_font = get_text_by_font(doc)\n",
    "        token_len_fonts = get_text_font_amount(text_by_font)\n",
    "        relevant_font = token_len_fonts[0][1]\n",
    "    except: \n",
    "        print(filename)\n",
    "        continue\n",
    "    # add relecant text to array\n",
    "    text_articles.append(text_by_font[relevant_font])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c6a1bb",
   "metadata": {},
   "source": [
    "### Divide corpus into sentences\n",
    "An article is often too long for our contextual model (comes later in the script), so we divide the text corpus into sentences instead using spacy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7546b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# english spacy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "946e5a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_lower = []\n",
    "for article in text_articles: \n",
    "    try: \n",
    "        doc = nlp(article)\n",
    "    except: \n",
    "        print(len(article))\n",
    "        continue\n",
    "    for sent in doc.sents: \n",
    "        sentences_lower.append(str(sent).lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6fd6f2",
   "metadata": {},
   "source": [
    "## Find ngrams in the text corpus\n",
    "In this example we will find bigrams of words, meaning two and two words from the text. \n",
    "We also filter out some of the bigrams based on non-albhabetic characters and frequency.\n",
    "\n",
    "As you increase the number of n-words in you ngrams the amount of different combinations also increase!\n",
    "\n",
    "In the filtering mechinism it is possible to add or remove filters, depending how strict you are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "426672f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we first join all the aritcles to one big text chunk with dubbel-line space and make it lowercased\n",
    "text_data = \" \\n\\n\".join(text_articles)\n",
    "text_list = word_tokenize(text_data.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5d7fdae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk has a in-built function for finding ngrams\n",
    "word_ngrams = nltk.ngrams(text_list, NGRAMS) # to make trigrams, 4grams ... change the number accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5a73286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we find how ofter each bigram occurs\n",
    "fdist = nltk.FreqDist(word_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f022b804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('et', 'al.', ','), 120), (('.', 'in', 'this'), 41), (('.', 'however', ','), 38), (('for', 'example', ','), 38), (('.', 'in', ','), 37), (('et', 'al', '.'), 34), (('the', 'number', 'of'), 33), (('.', 'for', 'example'), 32), ((')', '.', 'the'), 30), ((')', ',', 'and'), 28)]\n"
     ]
    }
   ],
   "source": [
    "# we print the 10 most common bigrams in the text \n",
    "print(fdist.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f89b98bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the rarest ngrams: should be at least 3 occurances, should include some albhabetic characters\n",
    "filtered_ngrams = []\n",
    "for k,v in fdist.items():\n",
    "    enough_occurances = (v > 2) \n",
    "    includes_character = all([bool(re.search(\"[a-z]+\", word)) for word in k])\n",
    "    if (enough_occurances and includes_character): \n",
    "        filtered_ngrams.append((k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5a37a742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56634 947\n"
     ]
    }
   ],
   "source": [
    "# print the amount of grams before and after filtering\n",
    "print(len(fdist.keys()), len(filtered_ngrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b303f905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we merge the two words with space to create a string of the bigram\n",
    "filtered_ngrams_list = [\" \".join(gram[0]) for gram in filtered_ngrams]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5092ed8c",
   "metadata": {},
   "source": [
    "## Embeddings from contextual model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97497dad",
   "metadata": {},
   "source": [
    "### Load contextual model: BERT\n",
    "BERT stands for Bidirectional Encoder Representations from Transformers and is a deep neural network pre-trained on a massive amount of text data. Paper:  https://arxiv.org/abs/1810.04805. Blog explaining BERT: https://jalammar.github.io/illustrated-bert/ . \n",
    "\n",
    "BERT has 12 stacked encoder layers, each token gets a new vector representation (hidden state) after each layer. Any of these can in principel be used as a word-representation, however it has been proven that later hidden states include more semantic value which we see as useful for this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89667fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4870461a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# define model name\n",
    "model = 'bert-base-uncased' #for norwegian you can use: 'NbAiLab/nb-bert-base' or 'ltgoslo/norbert'\n",
    "\n",
    "# the tokenizer plits the input text into tokens, which in this case is called wordpieces \n",
    "tokenizer = BertTokenizerFast.from_pretrained(model)\n",
    "\n",
    "# download the model online\n",
    "bert_model = BertModel.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa403aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change to cuda cores if a gpu is available\n",
    "bert_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5710a03e",
   "metadata": {},
   "source": [
    "### Obtain embeddings from BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "992a77fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert create a vector representation (actually many, one between each layer in the model)\n",
    "# this function fetches the tokens and embeddings \n",
    "def sent_to_embedding_tokens(sent): \n",
    "    with torch.no_grad(): \n",
    "        tokenized_sent = tokenizer.tokenize(sent)\n",
    "        # check if tokens are too long\n",
    "        if (len(tokenized_sent) > 500): \n",
    "            return False, False\n",
    "        # tokenize sentence to model inputs\n",
    "        inputs = tokenizer(sent, return_tensors = \"pt\")\n",
    "        # inference the inputs through the BERT model to obtain token-embeddings\n",
    "        outputs = bert_model(**inputs.to(device), output_hidden_states=True)\n",
    "        # according to the huggingface library, the 2. element contain all the hidden states\n",
    "        hidden_states = outputs[2]\n",
    "\n",
    "        token_embeddings = torch.stack(hidden_states, dim=0) #stack all hidden states into same tensor\n",
    "        token_embeddings = token_embeddings.squeeze(dim=1) # remove empty dimension\n",
    "        token_embeddings = token_embeddings.permute(1,0,2)[1:-1] # change dimensions and remove remove cls and sep token\n",
    "    \n",
    "    return tokenized_sent, token_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a402a230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_index2token_index(tokenized_sent, word_array): \n",
    "    current_word = word_array[0]\n",
    "    word_index = 0\n",
    "    word_index2token_index = {}\n",
    "    current_token = \"\"\n",
    "    for i, token in enumerate(tokenized_sent): \n",
    "        current_token += (re.sub(\"^##\", \"\", token)) # it is standard for BERT tokenizer to add ## for subpieces not first in a word\n",
    "        if (current_word == current_token): \n",
    "            if (word_index in word_index2token_index): \n",
    "                word_index2token_index[word_index].append(i)\n",
    "            else: \n",
    "                word_index2token_index.update({word_index: [i]})\n",
    "            word_index += 1\n",
    "            # check if it was the last word\n",
    "            if (len(word_array) <= word_index): \n",
    "                break\n",
    "            current_word = word_array[word_index]\n",
    "            current_token = \"\"\n",
    "        else: \n",
    "            if (word_index in word_index2token_index): \n",
    "                word_index2token_index[word_index].append(i)\n",
    "            else: \n",
    "                word_index2token_index.update({word_index: [i]})\n",
    "    return word_index2token_index\n",
    "\n",
    "def get_ngrams_and_indecies(word_index2token_index, word_array): \n",
    "    ngrams = [ngram for ngram in nltk.ngrams(word_array, NGRAMS)]\n",
    "    ngram_word_indecies = [[i+j for j in range(len(ngrams[0]))] for i in range(len(ngrams))]\n",
    "    ngram_token_indecies = []\n",
    "    for word_indecies in ngram_word_indecies:  \n",
    "        ngram_token_indecies.append([token_index for word_index in word_indecies for token_index in word_index2token_index[word_index]])\n",
    "    return ngrams, ngram_token_indecies\n",
    "\n",
    "\n",
    "def get_filtered_ngrams_in_sent(tokenized_sent, sent): \n",
    "    word_array = word_tokenize(sent)\n",
    "    word_index2token_index = get_word_index2token_index(tokenized_sent, word_array)\n",
    "    ngrams, ngram_token_indecies = get_ngrams_and_indecies(word_index2token_index, word_array)\n",
    "    # make the ngram of words into one string \n",
    "    ngrams_in_sent = [\" \".join(ngram) for ngram in ngrams]\n",
    "    \n",
    "    filtered_ngrams_in_sent = []\n",
    "    for i, ngram_in_sent in enumerate(ngrams_in_sent): \n",
    "        if(ngram_in_sent in filtered_ngrams_list): \n",
    "            filtered_ngrams_in_sent.append((ngram_in_sent, ngram_token_indecies[i]))\n",
    "            \n",
    "    return filtered_ngrams_in_sent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecbc6d3",
   "metadata": {},
   "source": [
    "### Create ngram-embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5eb0730c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_embedding_in_dict(ngram_phrase, ngram_embedding, ngram_embedding_dict): \n",
    "    if (ngram_phrase in ngram_embedding_dict): \n",
    "        old_embedding = ngram_embedding_dict[ngram_phrase][0]\n",
    "        old_occurances = ngram_embedding_dict[ngram_phrase][1] \n",
    "        \n",
    "        # here we use \"mean-pooling\" over all the contextual embeddings to obtain our static ngram-embedding\n",
    "        new_embedding = ngram_embedding/(old_occurances+1) + (old_embedding*old_occurances)/(old_occurances+1)\n",
    "        ngram_embedding_dict[ngram_phrase] = (new_embedding, old_occurances+1)\n",
    "    else: \n",
    "        ngram_embedding_dict.update({ngram_phrase: (ngram_embedding, 1)})\n",
    "        \n",
    "    return ngram_embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2fbd5906",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_embedding_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "107fd378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "���������������������������������� ����������������������������������������� ����������������������������������������� ����������������������������������������� �����������������������������������������\n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "each node  contains a set of lexicaliza- tions of the concept for diﬀerent languages, e.g., , , , . . .\n",
      "in order to build the babelnet graph, we collect at diﬀerent stages: a. from wordnet, all available word senses (as concepts) and all the lexical and semantic pointers between synsets (as relations); b. from wikipedia, all encyclopedic entries (i.e., wikipages, as concepts) and semantically unspeciﬁed relations from hyperlinked text.\n",
      "next, to enable multilinguality, we collect the lexical realizations of the available concepts in diﬀerent languages.\n",
      "we  by collecting all relations found in wordnet, as well as all wikipedias in the languages of interest: in order to encode the strength of association between synsets we compute their degree of correlation using a measure of relatedness based on the dice coeﬃcient.\n",
      "  \n",
      "for english, we might have two diﬀerent deﬁnitions, one from wordnet, one from wikipedia, if a link could be established.\n",
      "babel synsets contain many diﬀerent kinds of information available by means of its methods, among which we have: , which returns the synset id; , which provides the synset’s part-of-speech tag; , which returns the synset source, i.e. whether it belongs to wordnet only, wikipedia only or both (i.e. a mapping between a wikipedia page and a wordnet sense could be established); : does the synset denote a  or a ? , which returns the list of senses in the synset; , which returns a source-to-target map of the translations of babel senses; , which returns a map of all babel synsets connected to the given synset by means of lexical-semantic relations; , which returns a list of wikipedia categories for the given synset; , which returns a list of image uris for the given synset; , which returns a list of wordnet oﬀsets to which the synset is linked; , which returns the main sense of the synset.\n",
      "in ad- dition to these conventional approaches, the latest developments in neural language models have mo- tivated some researchers to include them in their wsd architectures (k˚ageb¨ack and salomonsson, 2016; melamud et al., 2016; yuan et al., 2016).\n",
      "since semi-supervised models have been shown to outperform fully supervised systems in some settings (taghipour and ng, 2015b; bas¸kaya and jurgens, 2016; iacobacci et al., 2016; yuan et al., 2016), we evaluate and compare models using both manually-curated and automatically-constructed sense-annotated corpora for training.\n",
      "neural language models have recently shown their potential for the wsd task (k˚ageb¨ack and salomonsson, 2016; yuan et al., 2016).\n",
      "  \n",
      "tim rockt¨aschel, edward grefenstette, moritz hermann, karl, tom´aˇs koˇcisk`y, and phil blunsom.\n",
      " \n",
      "������\u000b",
      "\n",
      "\f",
      "\u000f\u000e\u0010�\u0012\u0011\u0013\n",
      "\u000f\n",
      "\n",
      "�\u001e",
      "\u001d",
      "\u001f\u000e\u0010  !\n",
      "fonqp,rts=uvi<d\u0010d*lwpyxhg\u0010z[d*f\\z ]'\u00103:9<;='?>@'*a-)b\"43 ced*fhg\u001bikjml\n",
      "d_pa`\u0010i<jmb[c\\dfe*ztxgdfi<\n",
      "hjitxgfgd*k<lgk<fglmlgm*eni<d*d*lgi<`\u0010m oqp/r 9_3s'*tu9 vqw\u001c",
      "x_wzy<{}|k~ *w\u00164|qwz",
      "*wz|k~ wza{}w\u001c",
      "\n",
      "~ 4|wzym|<~ 4q4w ywz4y\u000fwzm\u0016\u0016w:x�{}\u0016|44y4y\u000fw:x~ q4w74%~ y\u0016 \u0016|kx_ymymyx wm4amqwq4wy<{}\u0016|wzyk  9¤£f¥3s¦=§ 4wqwzyex4m©{}\u00164yk~\n",
      "yqw:x©%ª1m44|k*~«¬mqw: ­�®\u0016¯°\u0016°\u0016° \u0016|kx_y±%ª²|%4y~ 4qwz[bª³|%«\u0012 \u001c",
      "\n",
      "v?\u0016j´\u0016q|wzwz µz\u0016%|y\u0016sm|~{z wzymyx\u001f\u00164w/wz\u001b{}wz|4¶ªo|%«q4w¸·y| \u0016|%4yk\n",
      "  4w5q4|wzwqqwz[qy¤|wz4|\u000fwzywz",
      "ºq4|\u000fwzw?x4~ y ~ y{}»x_%«¬\u0016~ %yk¼�\n",
      "w:x4~ q\u0016|k~\u0016¯²4w y½yq\u0016|\u000f­¾myx,¿y{} ~ \u0016y áà 4wz­ wz|w�{}y w:xbª³|%«âq4w�ã%wz% |wzwz ym4åääz  ",
      "ç\u0016wz|4yk¯:4\u001644y<¯%myxº\u0016x_èéw:{}~ ç\u0016wzy wz|w@x\u0016\u00164y wz m44\u0016mqw:x q²vq\u0016|kx4ê/wz¶ë\u0016 ì\u0016 ë¸íqî_w: ymy«©¯uë\u0016ï\u0016ï\u0016ð\u0016ñ ywz4y\u000fwzyk¯=max#q4wz\n",
      "�\u0016x_è\\\\u0082ax4~{zmqw:x±myxò{}\u0016||w:{}qw:x¤",
      "­\n",
      "  4w5m%4\u0016mq\u0016|y wz|\u000fwåwza{}\u00164| m\u0016w:xqå~ yx4~{zmqw@«a ~ \u0016|kxå{}\u00164yq|\u000fy{}~ \u00164y 4wz vq\u0016|kx4ê/wz{}\u0016",
      "\u0016~ %y±mm%4|\u00164|k~mqw\u001e",
      "wz[q|­:  4w m44\u0016mq\u0016|\u000fy wz|we\u0016 w:x²q²m \u0016|kx_y q\u001e",
      "«\u000b",
      "y ~ y wôy\u000fwz4ywzyk¯44 wz|w\u0019my\u0016w:xq\u000b",
      "y~{-¬1yk~ 4% wôy\u000fwz4yw 4wz%wzç\u0016wz|#\u0010\u0016y\u000fyk~ y w:  4w»m4%\u0016mq\u0016|y wz|w»\u0016 y my\u0016w:xõqå~ yx4~{zmqw\n",
      "%wz�\n",
      "4ywz4yw~ �vq\u0016|<x4êôwz/¿4qy q4wj«w:my~\n",
      "�%ªöq4w \u0016|kxfíq«¬m|\u0016w:\n",
      "x½mye×¸ñq  q\u0016\u0016%%ªùø\u0016¯ø\u0016ë\u0016ø \u0016|kx_y wz|wm\u0016\u0016w:x4 ·nw:{zm%yw y%«õw±%ªq4wzy\u000fw \u0016|<x_y wz|wym|#%ªe«\u000b",
      "y ~ \u0016|<x {}\u00164yq|\u000fy{}~ \u00164yk¯4q4wq\u0016\u0016u[y«\u000b",
      "*wz|%ª1m4y wz|y my ø\u0016¯°\u0016ð\u0016ë\u0016  4wz|\u000fw wz|wõmfç\u0016wz|km\u0016w\u001f%ª4ë\u0016 °\n",
      "îmó¶ëmêäôoíy1*wz| m4y wz|²\u0016ª³qwz|e\u0016x_èéyx4~{zm~ \u0016a  üý%þßý4à[áâ yw­\u001b w¾{}\u0016|4%yk¯ò~ ax4~{zm~ 44w:\u0016x ãäåkæ\u001bç<æéè\u001bêöêäëmìíîè\u001bêï ð\n",
      "ç<öoõ¶ûkü<äìëêöëm÷\u0016æéø(õéæ}ìù<äê ÷úìë\n",
      "ôoôoæéäöoç²û\u0016ë_ýwìþ<êùöoçäå<æ=èùýwÿmævëm÷öäå<æ¸ð\n",
      "ëmçkôoíöoõéê/ëmì äå<æ}ëmìæéäöoõ(ý-ô[ôoöoç müköoêäö³õ}ê ü<æ\u0010äë _ý-ìöoëmü<êuìæzýwêëmçkê\u000fîeþ<æ mìæéæéêôöoçeæ}ö³äåkæéìùõéë\n",
      "mî _ð\u0010ëm÷<äåkæéêæ*èöæéìæ*ü<\n",
      "÷[äå<ænêí(êäæéó¶ê \u001bå<æ =ìæéó¶ë æéþ\u000b",
      "öoç<êä\u000fýwçkõéæéê öoç<õéôoükþ<\n",
      "æ�ý-ü<ø(öoôoöéý-ìöoæéê\u000fî%èöëmìþ<ê\u001fè\u001båköoõ å¬þ<\n",
      "ìþ yæéä æéç(äìöoæéê\u000fîéöoç<\n",
      "êä\u000fýwçkõéæéê",
      "è\u001bö³äåôöoç<õ}ëmììæéõéä tìæéæ *ý-ç<ÿ1ùtýwìä\n",
      "ê\u000fî< áêù\u0016æéæéõwå ä\u000fý \n",
      "ìóýwä äæéþ\u0019ö³çkõéëmììæ}õéäôoí \u0016|kx_y�q*w#m\u0016\u0016w:/û\u0016æéæéç/÷úë\n",
      "x?\u0016 \u0016% q»ykmqw:~ qw \u0016|<x_y ª³\u0016|\u001c",
      "\n",
      "«a ~ \u0016|kx7wz",
      "%|wzyyk~ \u00164y<¯ my {}|w:mqw:x myx x4~ yq|<~ 44qw:x5qq%w¤ym|~{z~ am",
      "qy5\u0016 \u00164 q,q4w \u0016|k~ %~ y\u0016y­[",
      "\u0016{}~{¶myx\u000b",
      "ym|q%ª³y*wzw:{fm4%\u0016m~ \u0016 ª³|%« q4w |\u000fwzwzym4�ääå¿y wzyk  4wam|~{z~ ym[qy wz|wq%~ ç\u0016wz \u00164w wzwz,q|%bq%w:~ |#y­",
      "y\u000fqw:«õy#\u0016 q4wqwzy\u000fq\u000fx4m\n",
      "©myx�y4y«¬~ ¶q4w|wzyy qyk  $19_\"43 \u000f'*$=$/¥9_'*9_¥3 3s\"4\"4)b\"4$19 4w [qwz|\u000fm44\u0016mq\u0016| m\u0016|wzw:«õwz[8|<mqw q4w 4|wzam|km~ \u0016%ªq4w {}\u0016|%4y my,m%4|\u001b~«¬mqw: ì\u0016ø\u0016 ®\n",
      "ùwz|4y\u0019y\u0016x�q%wj wzy�m\u0016|wzw:«õwz[\u0019|kmqwºm ì\u0016 ð ¬¯ª³% w:x\u001e",
      "[­q4\u001644yºm#ì % ï myx�\u0016x_èéw:{} ~ ç\u0016wzy�m²ì\u0016ð\u0016 ® ¬  %w½x4~ ykm\u0016|wzw:«wz",
      "qy@qwzyx_w:xfq{z\n",
      "%yqwz|ºm|\u000f\u00164yx\n",
      "\u001f|\u000fw:m~ ç\u0016w: ­jyk«©\u0016s\u0016|\u0016%©%ª\u001bx4~ ½{}a \u0016|kx_yk  ¶a û\u0016ð\n",
      "%ª\u0016 \u0016|kx½w­[\u0010wzyfmyx®\u0016ì %ª \u0016|kx½w­[*wzy q«õ\u0016|w½qym?¿4ç\u0016w½q\u0016\u0016wz4yºy\u0016xbm",
      "­ x4~\n",
      "y<m\u0016|wzwz «õwz[²m²\u0016  ¶%w \u0016|kx qç\u0016wz|­� m\u0016|wzw:«õwz[ my�q4w \u0016x_èéw:{}~\n",
      "ç\u0016w ³ ùä}åyk~ ¬\u00164v%ªtywzç\u0016wz~ 4yma{}wzy \u00164wjm%4\u0016mq\u0016|e{-4\u0016ywy\u000fwz4yw %¼ y~ wq%w\u0016q4wz|em%4\u0016mq\u0016|e{-4\u0016ywywz%ywq4|wzw:¼ 4w\u000b",
      "|w:«¬\u0016~ y~ 4²¿4ç\u0016w\u000b",
      "y\u000fwz4ywzy wz|w\u00194wzç\u0016wz|=%yw:x4  4w «¬\u0016~ x4~ \u0010wz|wzy{}wõ*wz wzwz#q4wzywõ �ywz4y\u000fwzyvy\u000fwzw:«õy\n",
      "q5*w©qymeq4wªo\u0016|<«õwz|ºm%y~ wzy 4wz�q4wj%ywj%ª ~ y»~ ",
      "qwzax_w:x»qx_|k b{}\u0016[q|kmy q y%«õwzqa~ 4 ³¯/myxåq4wfmqqwz|jm%y~ wzy 4wz ~ y~ [qwzyx_w:\n",
      "xòq x_|k {}\u0016",
      "q|<my qy%«wzqy~ 4 ³  �*%~ [qy±m*\u00164ºqy~ y4\u0016ax*w8«¬\u0016x_w:¼ íq\u0016ñ»q4wzyw7\n",
      "ywz4ywzym|w {z \u0016yw: ­|w:mqw:x,myx~ \u001c",
      "\u0016{}qy\u0016ù4ywzy¬%ª/q4w \u0016|kx q«¬q­,\u0010w~«õ*\u0016yyk~ y w½qòèéyx_\u0016w y~{-,%ª\u001fq4w:« y«õ\u0016y�m%y~{zmy fíéyñ�q4wb\u0016{}qy\u0016ex4~ y~ a{}~ \u0016 *wz wzwzfq4w ¬y\u000fwz4ywzy\u001fy\u0016xeq¬*w¬~ yª³wz||w:xºª³|%« q4w% \u0016yy\u000fwzyk  4w% \u0016yywzy x_4\u0016q4w:«õy\u000fw: ç\u0016wzy «¬m\u0016wq%wywz4yw\n",
      "y~ y{}~ \u00164y\u0019wz",
      "y~{z~   ä},ªé\u0016{}¯ w©*w:~ wzç\u0016wåqymj«õ\u0016y\u000f%ªyq4w\u001e",
      "m%4\u0016m q\u0016|½x4~ y<m\u0016|wzw:«õwz[qy wz|w:¯\u000b",
      "~ \u0016wfqa~ y�wz*\u0016«õa w:¯ô*wz wzwz±{z \u0016yw: ­å|w:mqw:xevq\u0016|kx4ê/wz¶ywz4ywzy qº\u0016y y4% íqmyx%ª³qwz\n",
      "4wz[y~{z~\n",
      "ñòx4~ y~ y{}~ \u00164y�\n",
      "myx qym¬«õ\u0016|w#{}%m|ywz\u0016|<\u0016~ 4w:xåywz4yw#x4~ y~ a{}~ \u00164y©m|w 4wzw:x_w:x¤íqãa\u0016«wz|\u0019wz²\u0016 ¯nø\u0016°\u0016° %ñq  ./0 9<\"%) '\u0010$=27./tu¥n3s\" y\u000f­\n",
      "",
      "yqw:«y\n",
      "wz|\u000fw?y4a«¬~\n",
      "qqw:x�[­»q\u0016\u0016%ªºë qw:\u0016«õyk  4wqy­[yqw:« y\u0016«wzyk¯�\u0016 \u00164 q w:«¬\u0016~ {}\u0016[\u0016{}qym|\u000fw²~ yqw:x©~ ©my weû\u0016  ywzqy=%ªsyk{}\u0016|\u000fwzy wz|wj{}%«õ4%qw:xfªo\u0016|\u000b",
      "w:\u0016{\n",
      "\u001e",
      "y­",
      "y\u000fqw:«¬  î_\u0016|\u0019q4w¿4|\u000fy\u001fywz%ªöyk{}\u0016|wzy@í wv q×\n",
      "\u0016ñq¯ wåmy yy«w:xm m4y wz|¬%ªõ× íé4",
      "m\u0016%ma w:ñ %wz4wzç\u0016wz| q4w@y­[yqw:«âªé\u0016~ w:xºq#4|kç*~x_wf²ywz4y\u000fw:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [4yõq4w 4yma{}w \u0016yx\u001f*wôyk{}\u0016|\u000fw:xmy\u001f{}\u0016||w:{}v~ª<q%w\u0019m4y wz| \u0016wz­©\u0016 y²«©m|\u0016w:x~ =my¶×\u0019¯:myx~ y{}\u0016|\u000f|w:{}\u0016q4wz| yw:\n",
      "  î_\u0016|eq4w¬y\u000fw:{}\u0016yx#ywz²%ªyyk{}\u0016|wzy#í wv q4\u0016%º× \u0016ñq¯ wvy<~«õy ­y\u001b~ 4*w:x\u000b",
      "wzç\u0016wz|­º~ %ymy{}w 4wz|wvq4w¶y­[y qw:«x4~x¸4\u001614|\u000fç\u001b~x_w/y\u000fwz4yw:  [4yy%|w:{z~ yk~ \u0016 my 4\u0016º\n",
      "öw:{}qw:x½[­\u001e",
      "q%\u0016yw\u001e",
      "~ 4y\u000fmy{}wzyk¯y44|\u000fw:{z\u0016 my wz|w:x4  ç\u0016wz q4\u00164\u0016\u0013m[­?%~ ç\u0016wz\u001c",
      "\n",
      "qw:\u0016« «¬q­byç\u0016w,~ 4 qwzyx_w:x\u000b",
      "q4w:~ |a|wzyy qyaqõ*w\u0019~ ",
      "qwz|\u000f4|wzqw:x\u0019\u00164w ­\u0016| q4we\u0016q4wz|k¯ w²yç\u0016wf~ y{z yx_w:x©*\u0016q½ywzqyõ%ª\u0010yk{}\u0016|\u000fwzy\n",
      "ª³\u0016|5{}%«õam|km~ ç\u0016w544|*\u0016ywzyk  my wëfy% yåq4w\n",
      "y­[yqw:« *wz|kª³\u0016|k«¬ma{}w¬4yx_wz|q%w¬¿4|yå~ ",
      "qwz|%|wzm ~ \u0016�%ª:q4w¶|wzyy qy\u000b",
      "í wv~ q½× \u0016ñq  4wqç\u0016wz|km\u0016w\u000b",
      "4|wz {z~ yk~ \u0016myx@|w:{z\u0016~ y@®\u0016ø\u0016 ø ¬  my w¬ø¸y4 y¶q4wõy­",
      "y\u000fqw:« \u0010wz|<ªo\u0016|k«©my{}w\u0019%yx_wz| q4w\u0019yw:{}\u0016yxº~ ",
      "qwz|\u000f4|wzm~ \u0016º%ªtq4w\u0019|wzyy qyí wv q%\n",
      "\u00164ò× \u0016ñq  4w,ç\u0016wz|km\u0016wò%|w:{z~ yk~ \u0016 y�®\u0016ì\u0016  myx ®\u0016ë\u0016 ï\n",
      "yq4wjç\u0016wz|km\u0016w²|\u000fw:{z\u0016  ´4~ a{}w#{}%«4|wz4wz4y<~ ç\u0016we\u0016|\u000f\u00164y~ 4\u0016yõ%ª\u001bq%wevq\u0016|<x_ ê/wzvy\u000fwz4ywzyx_²%\u0016=­\u0016wz¶wz\u001b~ y¯*\u0016:|\u000fwzyy qy¶%~ ç\u0016wz±m|w q4w|\u000fwzyy \u001f%ª%¿44wz\u0016|k\u0016~ 4w:x¬yk{}\u0016|k~ 4%  q4\u00164\u0016 w8x4~x¾4\u00167{}%«õ44qw8\u001c",
      "ymy\u000fw:~ 4w yk{}\u0016|w:¯ w@|w:{}w:~ ç\u0016w:xfywzç\u0016wz|k\u0016\u0010ymyw:~ %w�¿4\u00164|wzy¬ª³|%« \u00164|²ym|~{z~ ym[qyk  =wzy~\n",
      "ù4|wz¯y%ª ¶\u001b{¬×ôa~ ç\u0016wz| yk~ ­:¯4{}%«õ44qw:x@/ymyw:~ 4wv%ª °\n",
      "\u0016 ï b4|\u000fw:{z~ yk~ \u0016¤myx |w:{z\u0016\u0010[­¤4y<~ 4ºq4w@¿4|y¸vq\u0016|kx4ê/wzwz[q|­�ª³\u0016|q4w %~ ç\u0016wz \u0016|kx�myxòym|q%ª³y*wzw:{y\n",
      "  ·¶m| /w:{z\u0016x\u0016¯ %ªyq4w\u001e",
      "×/y~ ç\u0016wz|y<~ w­q%ª [ wz|myxºy%y«¬~ qqwz|%ª q4w 4 y­[yqw:«¬¯\u000b",
      "4|kç*~x_w:x½ymy\u000fw:~ 4w %ª ø\u0016  7%yk~ 4�q4wy<\u0016«õwj«õwzq4\u001bxfíéq4wºë\u0016 \n",
      "® 8x4~ª³ ª³wz|wzy{}w\u001c",
      "\n",
      "~ y,«\u0016y?~ \u0016w:\n",
      "­wz",
      "a\u0016~ 4w:x[­\u001c",
      "\n",
      "% w: q4wamyw:~ 4wy­[yqw:«õy¸x_w:\u0016 q\u001e",
      "«y ~ \u0016|kxj{}\u00164 yq|a{}~ \u00164y²myx@[­[44wzymqw:x\n",
      "\u0016|kx_y<ñq  £f¥$/tuaw§ +-¥$ qeq%w\n",
      "üý%þßý4à[áâ \u001b4%~ y#\u0016 \u0016|kx_yùmy\u001b¯ q4w²y4*wz|ç\u001b~ yw:x�y­[yqw:«õy�ªém|w:x½«\u000b",
      "y{-½*wzqqwz|¸qym í(êäæéó \u0016ìæéõéöoêöoëmç uæéõ(ý-ô³ô æéç<êæ [æ(ý-ìç<æéì ëzõ\n",
      "ìþ<ê æzýwç<oä\\\\u00ed _ð %ç môoöoêå ý-ô³ô áè\u0010ë\n",
      "ìþ<ê æzýwç<ë\n",
      "öoç áêöoó¶ù<ôoæ mð ükù áêåkó¶ó\n",
      "áæ(ý \u001bý _ñ\n",
      "ò ükù áükç<ö mæ gæzýè óvæéìô êí(êäæéóð ý-ü<äë õ}ô³ì óvæéìô êí(êäæéó ý-ü<äë aê ý-ô³ô aë\n",
      "êü mò my wë\u0016¼ wv\n",
      "q½× ¶yk{}\u0016|\u000fwzy %v\u000f´õ\u0016|ù\u000f×òy ¬j\u0016ª³qwz| q4wy­[yqw:« a\u0016«õw©~ yx4~{zmqwzyqamq4wy­[yqw:« my |wz*\u0016|qw:xºmy\u001fy4*wz|ç\u001b~ yw:\n",
      "ð ëzõ açkö æéìêöoäéí  yw:x4¯s|wzy*w:{} ~ ç\u0016w: ­:  í(êäæéó \u0016ìæéõéöoêöoëmç uæéõ(ý-ô³ô \n",
      "_ò öç môoöoêå ýwôoô áè\u0010ëmìþkê æ(ý-ç<öoç }ý-ôoô³èöëmìþkê æ(ý-ç<\n",
      "ð mð \u001bý mð ü<ù áêå<ó¶ó\n",
      "gæzýè mð _ð\n",
      "÷ ü<êêæ}ø \u0016ìëmû mñ _ñkö æéìêöoäéí\u001fë\n",
      "æ ü<ù áü<çkö \n",
      "ð ó¶æéìô êí(êäæéóð _ñ\n",
      "ð ýwükäë aê ó¶æéìô êí(êäæéó \u0016ò ýwôoô aëmêü mñ my wø\u0016¼ wv~ q4\u00164\u000b",
      "× vyk{}\u0016|wzy<¯_y\u0016|qw:\n",
      "x¸[­|w:{z\u0016 \u0010 \u000f´©\u0016|¸\u000f×y ¬±\u0016ª³qwz|õq4w²y\u000f­",
      "yqw:«¾y\u0016«wº~ yx%~{zmqwzy qym²q4w¬y­[yqw:« mye|wz*\u0016|qw:xmyy\u000f4*wz|ç*~ y\u000fw:\n",
      "xº\u0016| 44y\u000f4*wz|ç*~ y\u000fw:x4¯s|\u000fwzy*w:{}~\n",
      "çä\u000fý-õéä ýwükäë þköéý-çuý-ó \u0010êü<êêæéø oýwõ ükÿ ýwükäë aê þköéý-çuý-ó \u0010êü<êêæéø oýwõ ükÿ õéôoì ýè æéç \u0010õéôoìæéê\n",
      "êü ó¶ëmç(äëí \u0010þkôoêö ütý æéê ûuýwìä þkæéõ(ýwþkä \u0010üuý ³ý-õ û\u0016æ êäì\u000fýwùkùuý \u0010öoäõ öoä êäì\u000fýwùkùuý \u0010öoäõ öoä êäì\u000fýwùkùuý \u0010öoäõ öoä ëzõ açkö\n",
      "æéìêöoäéí þkíükìæéä \u0010ÿ(ü æéþkü äì\n",
      "ó æ(ý-ç<<õ}êæéë \u0010çkô³ù ëmìæ(ý oýwõ ÿ(ì \u001bý ùuý-ìÿ æéì \u0010ô\\\\u00fdwç mütý mæ}õéëmó¶ùkü<äæéì õéë\n",
      "öoç ôoôoü<öoêó \u0010ôoêö ükù\u0016õ æéê æ(ý-ç<öoç ¶êöoó¶ùkôoæ ôoôoü<öoêó \u0010ôoêö ükù\u0016õ æéê ó¶æéìô êí(êäæéóð ûkå<öoÿ(êåuý \u0010ó¶æéìô\n",
      "õéëmó ó¶æéìô êí(êäæéó ûkå<öoÿ(êåuý \u0010ó¶æéìô\n",
      "õéëmó ó¶æéìô êí(êäæéó ûkå<öoÿ(êåuý \u0010ó¶æéìô\n",
      "õéëmó ó¶ëmç(äëí \u0010þkôoêö ütý æéê æ}ç<êæ ",
      "æ(ýwìçkæéì ì\u000fýwþuý \u0010õéê ü<ç(ä æéþ<ü _ýwìõéö\\\\u00fd \u0010ükïý-æéç æéê ü<êêæéø \u0016ìëmû wü<þ<öoä\u000fý \u0016ìæéöoêê \u0010õéô õ(ýwó ³ý-õ ü<ÿ ü<êêæéø \u0016ìëmû\n",
      "wü<þ<öoä\u000fý \u0016ìæéöoêê \u0010õéô õ(ýwó ³ý-õ ü<ÿ ü<êêæéø \u0016ìëmû wü<þ<öoä\u000fý \u0016ìæéöoêê \u0010õéô õ(ýwó ³ý-õ ü<ÿ ü<ù áêå<ó¶ó\n",
      "gæzýè ý-ó¶ëmôoöoçuý \u0010þ<êöoõ ü<ù æéê ü<ù ý-ó¶ëmôoöoçuý \u0010þ<êöoõ ü<ù æéê ü<ù ý-ó¶ëmôoöoçuý \u0010þ<êöoõ ü<ù æéê my w¤û\u0016¼¸w:«¬\u0016~ô{}\u0016[\u0016{}åª³\u0016|w:\u0016{±y­",
      "y\u000fqw:« y\u000f\u0016|qw:x \u0016 4ym*wz~{z\u0016 ­:  q4w¸44y%\u0010wz|\u000fç*~ yw:\n",
      "xy­[yqw:«õyíqã1\u0016«õwz|\u001fwz\u0016 ¯\u001bø\u0016°\n",
      "\u0016ë\u0016ñq  ä}±ª\\\\u0089\u0016{}¯\u0016u%ª4q4wy\u000fwzç\u0016wzfy­[yqw:«õy|wz*\u0016|qw:x#my\u000b",
      "y4 *wz|ç\u001b~ yw:xõyk{}\u0016|w:xy~ \u00164wz|=qym\u001e",
      "m[­�%ª",
      "q4w\u000b",
      "a~ 4wy­[y qw:«õyù|wz*\u0016|qw:x�myù%4y4*wz|ç\u001b~ yw:xe~ e*\u0016q�4|\u000fw:{z~ yk~ \u0016 myx|w:{z\u0016*íé4yk~ 4²w:~ q4wz|¶%ª[q4w¸ ey<{}\u0016|k~ 4#{}|k~ qwz |k~\u0016ñq  %w\u0016|w:mqwzy�x4~ öwz|\u000fwzy{}w*wz wzwz\u001e",
      "q4wzyw|wzy\u000fy qy myx@q%\u0016yw%ªöq4w üý4þßký4à[áâ \u001b4%~ y�\u0016 \u0016|kx\u0016y my,~ yeqym#¬\u0016|\u000fw:mqwz|�\n",
      "",
      "y«\u000b",
      "\n",
      "*wz|%ªay­[yqw:«õy@yç\u0016w 4 \u0016{-y~ wzç\u0016w:xòyk{}\u0016|wzym©\u0016|qm*ç\u0016w\u001e",
      "q4w¤ymy\u000fw:~ 4w:  vby~ w©qy~ y²|wzyy å~ ywzy{}\u00164|<m%~ 4%¯=~ ²ywzw:«õy²qym q4w½\u0010wzy\u000f¬y­[yqw:«õy©aqç\u0016wºy~ \u001e",
      " \u0016\u0019~ ?q4w ®m ì\u0016° |km4\u0016w:  y~ y�~\n",
      "y\u001e",
      "4\u0016¤y\u000f4|4|k~ y<~ 4»%~ ç\u0016wz q4w w­[y~{z\u0016ö~ ",
      "qwz|\u000fm%4\u0016mq\u0016|õm\u0016|\u000fwzw:«õwz",
      "=%ª*ì\u0016°m\u000fì\u0016® ¾ª³\u0016| qy~ yºmy\u001b  vqwq*w:~ wzç\u0016wqqymªo%|q4wz|åyk~ \u0016y~ ¿y{zm[ 4|\u0016\u0016|\u000fwzyy «\u000b",
      "4y \u0016~ bq%wx_wzç\u0016w: \u0016y«wz",
      "b%ªå|wz y\u00164|<{}wzy q{}%m|\u000fywz|\u0016|k\u0016~ 4w:xqywz4ywqx4~ y~ y{}~ \u0016%y myx q% \u0016y\u000fywzyùqymvx\u0016|k wz",
      "a~{z~ \u001f{}\u0016[q|kmyqy1*wz wzwzq4wjywz4ywzy \u001e",
      "|wzy\u00164|k{}wzy#«õ\u0016|wåyy~ ma w5ª³\u0016| q4wmy\u000fqm\u000b",
      "ymyx4  5\" é\"43s\"4$=tu\" 4|<~ y~m4w?î_w: yma«¬¯õw:x4~ q\u0016|k ?\n",
      "ë\u0016ï\u0016ï\u0016ð\u0016  (  ã\u001b|\u000fwzyyk¯ \u0016«\u000b",
      "4|k~x\u0016\u0016w:¯ ¬æ m|qy ãa\u0016«wz|k¯ 4|<~\n",
      "y~m4w î\u0016w: ymy«¬¯\u001c",
      "´4{}\u0016q \u0016qq\u0016a¯ nm4|wz\n",
      "=w:ªoy<¯ùmyx ô% |km4 õm4%  ø\u0016\n",
      "\u0016ë\u0016 4%~ y\u001e",
      "my",
      "y<¼  \u0016|kx_y¬myx�ç\u0016wz|\u000f wz[ ~{z\u0016/yk\u0016«õy w: åä} ¯ \u0016y \u00164yw:¯nî_|kmy{}w:¯yµzy ­:  m|qy ã1\u0016«õwz|k¯  % ·¶m4\u0016\u0016 \u0016q­%\u0016¯ myx /%\n",
      "|km% õm4%  ø\u0016°\u0016° %  õ~ öwz|\u000fwz",
      "�\u0016|km[4 m|k~ ~ wzyª³\u0016|\u001e",
      "x4~ \u0010wz|wz[\u001e",
      "m4a~{zm~ \u00164yk ºä} \u001b¯y·n\u0016y\u000fq\u0016y¯ ©æ ­: \n",
      "however, the immense complexity of the object recognition task means that this prob- lem cannot be speciﬁed even by a dataset as large as imagenet, so our model should also have lots of prior knowledge to compensate for all the data we don’t have.\n",
      "the resultant architecture is somewhat similar to that of the “columnar” cnn employed by cire¸san et al.\n",
      "this technique reduces complex co-adaptations of neurons, since a neuron cannot rely on the presence of particular other neurons.\n",
      "since the ilsvrc-2012 test set labels are not publicly available, we cannot report test error rates for all the models that we tried.\n",
      "but these cannot be  read by the visually impaired persons.\n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "find the histogram of the image using ‗ ‘  function.\n",
      " \n",
      "   \n",
      "  \n",
      "  \n",
      "  \n",
      "for higher  dimensions  the  connectivity  is  calculated  by  conndef(ndims(bw), ‗maximal‘) formula.\n",
      "     \n",
      "     \n",
      "     \n",
      "  \n",
      "the felzenszwalb algorithm is not strictly monotonic, so the structure obtained cannot be cast into a tree:\n",
      "the felzenszwalb algorithm is not strictly monotonic, so the structure obtained cannot be cast into a tree:\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# interate through each sentence in the corpus to find ngram word-embeddings and add them to embedding dictionary\n",
    "for sent in sentences_lower: \n",
    "    try: \n",
    "        tokenized_sent, token_embeddings = sent_to_embedding_tokens(sent)\n",
    "        # we pick layer 11\n",
    "        # you can try changing the layer and see if it makes a difference\n",
    "        token_embeddings = token_embeddings.to(\"cpu\").detach().numpy()[:, 11, :]\n",
    "        ngrams_in_list = get_filtered_ngrams_in_sent(tokenized_sent, sent)\n",
    "\n",
    "        for ngram_tuple in ngrams_in_list: \n",
    "            ngram_embedding = np.mean(token_embeddings[ngram_tuple[1]], axis=0)\n",
    "            ngram_embedding_dict = insert_embedding_in_dict(ngram_tuple[0], ngram_embedding, ngram_embedding_dict)\n",
    "    except: # some text string do not work... \n",
    "        print(sent)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a2073a",
   "metadata": {},
   "source": [
    "## Make the embeddings comparable\n",
    "We use the gensim library only to avoid programming a \"most_similar\" function ourselves. With gensim you can however create you own word-embeddings from scratch based on architectures like W2V and Glove.\n",
    "Papers: https://arxiv.org/abs/1301.3781 (word2vec), https://nlp.stanford.edu/pubs/glove.pdf (Glove)\n",
    "\n",
    "The library als oprovide a simple storing format that lets us easiy save and reload the ngram word-embeddings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a89236b",
   "metadata": {},
   "source": [
    "### Store the embedding with gensim format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3f5a5bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_phrases = np.array(list(ngram_embedding_dict.keys()))\n",
    "ngram_embeddings = np.array([gram[0] for gram in ngram_embedding_dict.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ae876102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make word-embedding object from phrase embedding\n",
    "word_model = KeyedVectors(vector_size = len(ngram_embeddings[0]))\n",
    "word_model.add_vectors(ngram_phrases, ngram_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d8fac562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save word-embeddings\n",
    "word_model.save(\"academic_ngrams_\"+str(NGRAMS)+\".kv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2bab08",
   "metadata": {},
   "source": [
    "### Test embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9da686ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('total number of', 0.919865608215332),\n",
       " ('the total number', 0.9170092344284058),\n",
       " ('to the number', 0.9020191431045532),\n",
       " ('number of candidate', 0.8967668414115906),\n",
       " ('the amount of', 0.8795346021652222),\n",
       " ('number of sense', 0.877122163772583),\n",
       " ('number of classes', 0.8755532503128052),\n",
       " ('the set of', 0.8666863441467285),\n",
       " ('the size of', 0.8664100170135498),\n",
       " ('the distribution of', 0.8662344813346863)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_model.most_similar(\"the number of\", topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db64211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8295ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_model.most_similar(\"which is\", topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "55311707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to predict', 0.9140162467956543),\n",
       " ('to analyze', 0.9064823389053345),\n",
       " ('model to', 0.8878662586212158),\n",
       " ('to compute', 0.8809579014778137),\n",
       " ('to consider', 0.8785991668701172),\n",
       " ('to generate', 0.8775368332862854),\n",
       " ('to find', 0.8672257661819458),\n",
       " ('to evaluate', 0.8653639554977417),\n",
       " ('to produce', 0.85838782787323),\n",
       " ('to perform', 0.8545425534248352)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_model.most_similar(\"to model\", topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bea80bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('obtain', 0.77354496717453),\n",
       " ('find', 0.7476672530174255),\n",
       " ('collect', 0.7277253866195679),\n",
       " ('obtained', 0.7158311605453491),\n",
       " ('produce', 0.7151602506637573),\n",
       " ('ment', 0.7069098949432373),\n",
       " ('obtaining', 0.705387532711029),\n",
       " ('make', 0.7046814560890198),\n",
       " ('generate', 0.7044810056686401),\n",
       " ('take', 0.7010329365730286)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_model.most_similar(\"get\", topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c46400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee2b757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

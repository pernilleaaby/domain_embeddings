{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c2098b9",
   "metadata": {},
   "source": [
    "# Create ngram embedding\n",
    "A ngram of words is just a set of words: \n",
    "- Monograms: \"of\", \"words\", \"is\"\n",
    "- Bigrams: \"of words\", \"words is\", \"is just\"\n",
    "- Trigrams: \"of words is\", \"words is just\"\n",
    "- etc. \n",
    "\n",
    "A word-embedding is a vector representation of a word (random, simplified examples): \n",
    "- \"of\" -> [2, 6, -1]\n",
    "- \"words\" -> [-2, 3, 9]\n",
    "- \"just\" -> [9, 9, -3]\n",
    "\n",
    "The nice thing about word-embeddings is that you can compare words using mathematical functions like cosine similarity (cos_sim): \n",
    "- cos_sim(vector(\"cat\"), vector(\"tiger\")) = 0.95, where cos_sim is a score of similarity between two words. \n",
    "\n",
    "If we would like to find a vector for a ngram more than one we need a pooling function. A pooling function can for example be average, maximum, minimal, absolute maximum etc. \n",
    "- average_pooling([1, 2, 3], [3, 2, 1]) = [4, 4, 4]\n",
    "- abs_max_pooling([-1, -1, -3], [3, 2, 1]) = [3, 2, -3]\n",
    "\n",
    "\n",
    "## Text corpus\n",
    "For this notebook we will extract ngram of words from papers and embed them into ngram-embeddings. \n",
    "When we have the set of ngram-embeddings we can use a similarity function to find \"similar ngrams\" to what you input. \n",
    "We will in this tutorial support .pdf or .txt files. \n",
    "\n",
    "## Contextual model\n",
    "We are not going to train any models in this tutorial, but rather use an existing contextual language model to find our embeddings.\n",
    "\n",
    "These contextual models have often been pre-trained on a massive amount of data, so they already know a lot about a language. \n",
    "\n",
    "## NLP Libraries\n",
    "We introduce a few highly useful NLP- libraries, that you can use for a lot more than what we do in this tutorial!\n",
    "\n",
    "### Huggingface\n",
    "https://huggingface.co/ \n",
    "Huggingface is a library full of useful datasets and pre-trained langugage models, as well as an api to make the work with huge models simple for you. We will use it to download a pre-trained bert-model, but you can acces so many other models as well. \n",
    "If you for example want to download you own multilingual translation model check out facebooks: https://huggingface.co/facebook/m2m100_418M . \n",
    "\n",
    "\n",
    "### Spacy\n",
    "https://spacy.io/ \n",
    "Spacy is also a much used library in NLP. Although we in this tutorial mainly use it for splitting text into sentences, spacy models often has much more functionality. You can f.eks. do Named Entity Recognition, POS-tagging (tag words as verbs, nouns etc). \n",
    "\n",
    "\n",
    "### Gensim\n",
    "https://radimrehurek.com/gensim/intro.html\n",
    "Gensim is a library specialized in representing text as semantic vectors (as out word-embeddings). You can very easily create you own set of word-embeddings or document-embeddings with this library, however we use it mainly to get functionality when comparing the word-embeddings. \n",
    "\n",
    "\n",
    "### Pymupdf\n",
    "https://pymupdf.readthedocs.io/en/latest/\n",
    "Helpful for extracting information such as text or images from pdf-files. \n",
    "\n",
    "\n",
    "### Pytorch \n",
    "https://pytorch.org/\n",
    "Like Tensorflow, Pytorch is a framework for tensor-processing. Compatible with GPU. \n",
    "\n",
    "### Natural Language Toolkit (NLTK)\n",
    "https://www.nltk.org/ \n",
    "Superuseful for tokenization (e.g. creating our ngram of words) and it has a lot of useful lexical resources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be4ed77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\perni\\miniconda3\\envs\\tf_env\\lib\\site-packages\\requests\\__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.6) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# glob is used for finding filepaths\n",
    "import glob\n",
    "\n",
    "# regex\n",
    "import re\n",
    "\n",
    "# numpy, useful for efficient vector operations\n",
    "import numpy as np\n",
    "\n",
    "# pymupdf for pdf parsing (I have no idea why it is called fitz...)\n",
    "import fitz\n",
    "\n",
    "# natural langauge toolkit\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# pytorch \n",
    "import torch\n",
    "\n",
    "# transformoer models from huggingface\n",
    "from transformers import BertTokenizerFast, BertModel\n",
    "\n",
    "# spacy library\n",
    "import spacy\n",
    "\n",
    "# gensim library\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34fb105a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants \n",
    "PDF_FOLDER = \"D:/master_papers/Papers/*/*.pdf\"\n",
    "NGRAMS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c576061",
   "metadata": {},
   "source": [
    "## Fetch data from pdf-files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ade14e",
   "metadata": {},
   "source": [
    "### Define a few functions for extracting only relevant text\n",
    "Based on the format that pymupdf outputs a parsed pdf we only extract the text. The text is grouped according to which font they use. The aim is then to only extract the text of the main font to avoid bibliography etc. to be included in the text corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ebf9f462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_by_font(doc): \n",
    "    text_by_font = {}\n",
    "    for page in doc.pages(): \n",
    "        text_page = page.get_text(\"dict\")\n",
    "        for block in text_page['blocks']: \n",
    "            if ('lines' in block):\n",
    "                for line in block['lines']: \n",
    "                    for span in line['spans']: \n",
    "                        font_id = span['font']+\"_\"+str(round(span['size'])) # font_id equals font + size\n",
    "                        if (font_id in text_by_font): \n",
    "                            text_by_font[font_id] += (\" \"+span['text'])\n",
    "                        else: \n",
    "                            text_by_font.update({font_id: span['text']})\n",
    "    return text_by_font\n",
    "\n",
    "\n",
    "def get_text_font_amount(text_by_font): \n",
    "    token_len_fonts = []\n",
    "    for font_id, text in text_by_font.items(): \n",
    "        token_len = len(text.split())\n",
    "        token_len_fonts.append((token_len, font_id))\n",
    "    # sort so the one with the most tokens are first\n",
    "    token_len_fonts.sort(reverse = True)\n",
    "    return token_len_fonts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b965ad",
   "metadata": {},
   "source": [
    "### Extract text from the given pdf-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c19226b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the filenames,  probably in format: paper_folder/*.pdf \n",
    "filenames = glob.glob(PDF_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "30dbb0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through all filenames to extract text from each file\n",
    "text_articles = []\n",
    "\n",
    "for filename in filenames[:20]: \n",
    "    # parse pdf\n",
    "    doc = fitz.open(filename) \n",
    "    if (len(doc) > 20): # we skip very long files\n",
    "        continue \n",
    "    # we use a try catch, because some pdf-files do not work\n",
    "    try: \n",
    "        # find the text belonging to the most common font\n",
    "        text_by_font = get_text_by_font(doc)\n",
    "        token_len_fonts = get_text_font_amount(text_by_font)\n",
    "        relevant_font = token_len_fonts[0][1]\n",
    "    except: \n",
    "        #print(filename)\n",
    "        continue\n",
    "    # add relecant text to array\n",
    "    text_articles.append(text_by_font[relevant_font])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c6a1bb",
   "metadata": {},
   "source": [
    "### Divide corpus into sentences\n",
    "An article is often too long for our contextual model (comes later in the script), so we divide the text corpus into sentences instead using spacy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b7546b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# english spacy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "946e5a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_lower = []\n",
    "for article in text_articles: \n",
    "    try: \n",
    "        doc = nlp(article)\n",
    "    except: \n",
    "        print(len(article))\n",
    "        continue\n",
    "    for sent in doc.sents: \n",
    "        sentences_lower.append(str(sent).lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6fd6f2",
   "metadata": {},
   "source": [
    "## Find ngrams in the text corpus\n",
    "In this example we will find bigrams of words, meaning two and two words from the text. \n",
    "We also filter out some of the bigrams based on non-albhabetic characters and frequency.\n",
    "\n",
    "As you increase the number of n-words in you ngrams the amount of different combinations also increase!\n",
    "\n",
    "In the filtering mechinism it is possible to add or remove filters, depending how strict you are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "426672f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we first join all the aritcles to one big text chunk with dubbel-line space and make it lowercased\n",
    "text_data = \" \\n\\n\".join(text_articles)\n",
    "text_list = word_tokenize(text_data.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5d7fdae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk has a in-built function for finding ngrams\n",
    "word_ngrams = nltk.ngrams(text_list, NGRAMS) # to make trigrams, 4grams ... change the number accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5a73286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we find how ofter each bigram occurs\n",
    "fdist = nltk.FreqDist(word_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f022b804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((',',), 3339), (('the',), 3313), (('.',), 2552), (('of',), 1731), (('and',), 1336), (('a',), 1260), (('to',), 1126), (('in',), 1125), (('is',), 891), (('we',), 802)]\n"
     ]
    }
   ],
   "source": [
    "# we print the 10 most common bigrams in the text \n",
    "print(fdist.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f89b98bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the rarest ngrams: should be at least 3 occurances, should include some albhabetic characters\n",
    "filtered_ngrams = []\n",
    "for k,v in fdist.items():\n",
    "    enough_occurances = (v > 2) \n",
    "    includes_character = all([bool(re.search(\"[a-z]+\", word)) for word in k])\n",
    "    if (enough_occurances and includes_character): \n",
    "        filtered_ngrams.append((k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5a37a742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8739 2514\n"
     ]
    }
   ],
   "source": [
    "# print the amount of grams before and after filtering\n",
    "print(len(fdist.keys()), len(filtered_ngrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b303f905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we merge the two words with space to create a string of the bigram\n",
    "filtered_ngrams_list = [\" \".join(gram[0]) for gram in filtered_ngrams]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5092ed8c",
   "metadata": {},
   "source": [
    "## Embeddings from contextual model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97497dad",
   "metadata": {},
   "source": [
    "### Load contextual model: BERT\n",
    "BERT stands for Bidirectional Encoder Representations from Transformers and is a deep neural network pre-trained on a massive amount of text data. Paper:  https://arxiv.org/abs/1810.04805. Blog explaining BERT: https://jalammar.github.io/illustrated-bert/ . \n",
    "\n",
    "BERT has 12 stacked encoder layers, each token gets a new vector representation (hidden state) after each layer. Any of these can in principel be used as a word-representation, however it has been proven that later hidden states include more semantic value which we see as useful for this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "89667fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4870461a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# define model name\n",
    "model = 'bert-base-uncased' #for norwegian you can use: 'NbAiLab/nb-bert-base' or 'ltgoslo/norbert'\n",
    "\n",
    "# the tokenizer plits the input text into tokens, which in this case is called wordpieces \n",
    "tokenizer = BertTokenizerFast.from_pretrained(model)\n",
    "\n",
    "# download the model online\n",
    "bert_model = BertModel.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa403aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change to cuda cores if a gpu is available\n",
    "bert_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5710a03e",
   "metadata": {},
   "source": [
    "### Obtain embeddings from BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "992a77fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert create a vector representation (actually many, one between each layer in the model)\n",
    "# this function fetches the tokens and embeddings \n",
    "def sent_to_embedding_tokens(sent): \n",
    "    with torch.no_grad(): \n",
    "        tokenized_sent = tokenizer.tokenize(sent)\n",
    "        # check if tokens are too long\n",
    "        if (len(tokenized_sent) > 500): \n",
    "            return False, False\n",
    "        # tokenize sentence to model inputs\n",
    "        inputs = tokenizer(sent, return_tensors = \"pt\")\n",
    "        # inference the inputs through the BERT model to obtain token-embeddings\n",
    "        outputs = bert_model(**inputs.to(device), output_hidden_states=True)\n",
    "        # according to the huggingface library, the 2. element contain all the hidden states\n",
    "        hidden_states = outputs[2]\n",
    "\n",
    "        token_embeddings = torch.stack(hidden_states, dim=0) #stack all hidden states into same tensor\n",
    "        token_embeddings = token_embeddings.squeeze(dim=1) # remove empty dimension\n",
    "        token_embeddings = token_embeddings.permute(1,0,2)[1:-1] # change dimensions and remove remove cls and sep token\n",
    "    \n",
    "    return tokenized_sent, token_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a402a230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_index2token_index(tokenized_sent, word_array): \n",
    "    current_word = word_array[0]\n",
    "    word_index = 0\n",
    "    word_index2token_index = {}\n",
    "    current_token = \"\"\n",
    "    for i, token in enumerate(tokenized_sent): \n",
    "        current_token += (re.sub(\"^##\", \"\", token)) # it is standard for BERT tokenizer to add ## for subpieces not first in a word\n",
    "        if (current_word == current_token): \n",
    "            if (word_index in word_index2token_index): \n",
    "                word_index2token_index[word_index].append(i)\n",
    "            else: \n",
    "                word_index2token_index.update({word_index: [i]})\n",
    "            word_index += 1\n",
    "            # check if it was the last word\n",
    "            if (len(word_array) <= word_index): \n",
    "                break\n",
    "            current_word = word_array[word_index]\n",
    "            current_token = \"\"\n",
    "        else: \n",
    "            if (word_index in word_index2token_index): \n",
    "                word_index2token_index[word_index].append(i)\n",
    "            else: \n",
    "                word_index2token_index.update({word_index: [i]})\n",
    "    return word_index2token_index\n",
    "\n",
    "def get_ngrams_and_indecies(word_index2token_index, word_array): \n",
    "    ngrams = [ngram for ngram in nltk.ngrams(word_array, NGRAMS)]\n",
    "    ngram_word_indecies = [[i+j for j in range(len(ngrams[0]))] for i in range(len(ngrams))]\n",
    "    ngram_token_indecies = []\n",
    "    for word_indecies in ngram_word_indecies:  \n",
    "        ngram_token_indecies.append([token_index for word_index in word_indecies for token_index in word_index2token_index[word_index]])\n",
    "    return ngrams, ngram_token_indecies\n",
    "\n",
    "\n",
    "def get_filtered_ngrams_in_sent(tokenized_sent, sent): \n",
    "    word_array = word_tokenize(sent)\n",
    "    word_index2token_index = get_word_index2token_index(tokenized_sent, word_array)\n",
    "    ngrams, ngram_token_indecies = get_ngrams_and_indecies(word_index2token_index, word_array)\n",
    "    # make the ngram of words into one string \n",
    "    ngrams_in_sent = [\" \".join(ngram) for ngram in ngrams]\n",
    "    \n",
    "    filtered_ngrams_in_sent = []\n",
    "    for i, ngram_in_sent in enumerate(ngrams_in_sent): \n",
    "        if(ngram_in_sent in filtered_ngrams_list): \n",
    "            filtered_ngrams_in_sent.append((ngram_in_sent, ngram_token_indecies[i]))\n",
    "            \n",
    "    return filtered_ngrams_in_sent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecbc6d3",
   "metadata": {},
   "source": [
    "### Create ngram-embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5eb0730c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_embedding_in_dict(ngram_phrase, ngram_embedding, ngram_embedding_dict): \n",
    "    if (ngram_phrase in ngram_embedding_dict): \n",
    "        old_embedding = ngram_embedding_dict[ngram_phrase][0]\n",
    "        old_occurances = ngram_embedding_dict[ngram_phrase][1] \n",
    "        \n",
    "        # here we use \"mean-pooling\" over all the contextual embeddings to obtain our static ngram-embedding\n",
    "        new_embedding = ngram_embedding/(old_occurances+1) + (old_embedding*old_occurances)/(old_occurances+1)\n",
    "        ngram_embedding_dict[ngram_phrase] = (new_embedding, old_occurances+1)\n",
    "    else: \n",
    "        ngram_embedding_dict.update({ngram_phrase: (ngram_embedding, 1)})\n",
    "        \n",
    "    return ngram_embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2fbd5906",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_embedding_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "107fd378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interate through each sentence in the corpus to find ngram word-embeddings and add them to embedding dictionary\n",
    "for sent in sentences_lower: \n",
    "    try: \n",
    "        tokenized_sent, token_embeddings = sent_to_embedding_tokens(sent)\n",
    "        # we pick layer 11\n",
    "        # you can try changing the layer and see if it makes a difference\n",
    "        token_embeddings = token_embeddings.to(\"cpu\").detach().numpy()[:, 11, :]\n",
    "        ngrams_in_list = get_filtered_ngrams_in_sent(tokenized_sent, sent)\n",
    "\n",
    "        for ngram_tuple in ngrams_in_list: \n",
    "            ngram_embedding = np.mean(token_embeddings[ngram_tuple[1]], axis=0)\n",
    "            ngram_embedding_dict = insert_embedding_in_dict(ngram_tuple[0], ngram_embedding, ngram_embedding_dict)\n",
    "    except: # some text string do not work... \n",
    "        #print(sent)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a2073a",
   "metadata": {},
   "source": [
    "## Make the embeddings comparable\n",
    "We use the gensim library only to avoid programming a \"most_similar\" function ourselves. With gensim you can however create you own word-embeddings from scratch based on architectures like W2V and Glove.\n",
    "Papers: https://arxiv.org/abs/1301.3781 (word2vec), https://nlp.stanford.edu/pubs/glove.pdf (Glove)\n",
    "\n",
    "The library als oprovide a simple storing format that lets us easiy save and reload the ngram word-embeddings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a89236b",
   "metadata": {},
   "source": [
    "### Store the embedding with gensim format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3f5a5bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_phrases = np.array(list(ngram_embedding_dict.keys()))\n",
    "ngram_embeddings = np.array([gram[0] for gram in ngram_embedding_dict.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ae876102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make word-embedding object from phrase embedding\n",
    "word_model = KeyedVectors(vector_size = len(ngram_embeddings[0]))\n",
    "word_model.add_vectors(ngram_phrases, ngram_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d8fac562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save word-embeddings\n",
    "word_model.save(\"academic_ngrams_\"+str(NGRAMS)+\".kv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2bab08",
   "metadata": {},
   "source": [
    "### Test embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9da686ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('amount', 0.8376054763793945),\n",
       " ('numbers', 0.8167323470115662),\n",
       " ('count', 0.7815552949905396),\n",
       " ('total', 0.772007942199707),\n",
       " ('many', 0.7561793923377991),\n",
       " ('size', 0.7419945001602173),\n",
       " ('length', 0.73164302110672),\n",
       " ('multiple', 0.7314307689666748),\n",
       " ('list', 0.729461133480072),\n",
       " ('several', 0.7188810110092163)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_model.most_similar(\"number\", topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db64211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
